{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-beee091194c6>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-beee091194c6>\"\u001b[1;36m, line \u001b[1;32m30\u001b[0m\n\u001b[1;33m    state 0(initial=0.50)\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#http://aimotion.blogspot.ie/2011/05/hidden-markov-models.html\n",
    "\n",
    "import ghmm\n",
    "\n",
    "# setting 0 for Heads and 1 for Tails as our Alphabet \n",
    "sigma = ghmm.IntegerRange(0, 2)\n",
    "\n",
    "# transition matrix: rows and columns means origin and destiny states\n",
    "transitions_probabilities = [\n",
    "    [0.9, 0.1], # 0: fair state\n",
    "    [0.1, 0.9], # 1: biased state\n",
    "]\n",
    "\n",
    "# emission matrix: rows and columns means states and symbols respectively\n",
    "emissions_probabilities = [\n",
    "    [0.5, 0.5], # 0: fair state emissions probabilities\n",
    "    [0.75, 0.25], # 1: biased state emissions probabilities\n",
    "]\n",
    "\n",
    "# probability of initial states\n",
    "pi = [0.5, 0.5] # equal probabilities for 0 and 1\n",
    "hmm = ghmm.HMMFromMatrices(\n",
    "    sigma,\n",
    "    # you can model HMMs with others emission probability distributions\n",
    "    ghmm.DiscreteDistribution(sigma),    \n",
    "    transitions_probabilities,\n",
    "    emissions_probabilities,\n",
    "    pi\n",
    ")\n",
    "print hmm\n",
    "DiscreteEmissionHMM(N=2, M=2)\n",
    "state 0(initial=0.50)\n",
    "Emissions: 0.50, 0.50\n",
    "Transitions: ->0 (0.90), ->1 (0.10)\n",
    "state 1 (initial=0.50)\n",
    "Emissions: 0.75, 0.25\n",
    "Transitions: ->0 (0.10), ->1 (0.90)\n",
    "\n",
    "#Now that we have our HMM object on the hand we can play with it. Suppose you have the given sequence of coin tosses and you would like to distinguish which coin was being used at a given state:\n",
    "\n",
    "tosses = [1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
    "\n",
    "#The viterbi algorithm can be used to trace the most probable states at each coin toss according to the HMM distribution:\n",
    "\n",
    "# not as pythonic is could be :-/\n",
    "sequence = ghmm.EmissionSequence(sigma, tosses)\n",
    "\n",
    "viterbi_path, _ = hmm.viterbi(sequence)\n",
    "\n",
    ">>> print viterbi_path\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
